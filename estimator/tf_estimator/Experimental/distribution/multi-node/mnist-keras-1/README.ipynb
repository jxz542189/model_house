{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "try:\n",
    "  ROOT_DIR = 'gs://{}'.format(bucket_name)\n",
    "except NameError:\n",
    "  ROOT_DIR = './tutorial'\n",
    "  \n",
    "MODEL_NAME = 'mnist-with-keras-estimator'\n",
    "DATA_DIR = '{}/data'.format(ROOT_DIR)\n",
    "MODEL_DIR = '{}/{}'.format(ROOT_DIR, MODEL_NAME)\n",
    "EXPORT_DIR = '{}/{}/export'.format(ROOT_DIR, MODEL_NAME)\n",
    "CHECKPOINT_PATH = '{}/checkpoint'.format(MODEL_DIR)\n",
    "\n",
    "# Remove CHECKPOINT_DIR if needed\n",
    "if tf.gfile.IsDirectory(MODEL_DIR):\n",
    "  tf.logging.info('delete {}'.format(MODEL_DIR))\n",
    "  tf.gfile.DeleteRecursively(MODEL_DIR)\n",
    "  \n",
    "if not tf.gfile.IsDirectory(DATA_DIR):\n",
    "  tf.logging.info('create {}'.format(DATA_DIR))\n",
    "  tf.gfile.MkDir(ROOT_DIR)\n",
    "  tf.gfile.MkDir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save input data in TFRecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "X_train = train[0][:-5000]\n",
    "y_train = train[1][:-5000]\n",
    "X_eval = train[0][-5000:]\n",
    "y_eval = train[1][-5000:]\n",
    "X_test = test[0]\n",
    "y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_example(image, label):  \n",
    "  feature={\n",
    "      'image': _bytes_feature(image.tobytes()),\n",
    "      'label': _bytes_feature(label.tobytes())}\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def convert_to_tfrecord(images, labels, output_file):\n",
    "  with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "    for image, label in zip(images, labels):\n",
    "      example = create_example(image, label)\n",
    "      record_writer.write(example.SerializeToString())\n",
    "      \n",
    "      \n",
    "convert_to_tfrecord(X_train, y_train,\n",
    "                    output_file='{}/train.tfrecord'.format(DATA_DIR))\n",
    "convert_to_tfrecord(X_eval, y_eval,\n",
    "                    output_file='{}/eval.tfrecord'.format(DATA_DIR))\n",
    "convert_to_tfrecord(X_test, y_test,\n",
    "                    output_file='{}/test.tfrecord'.format(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "N_EPOCHS = 1\n",
    "  \n",
    "def generate_input_fn(file_pattern, mode, batch_size=BATCH_SIZE, count=N_EPOCHS):\n",
    "  \n",
    "  def parse_record(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.string),            \n",
    "        })\n",
    "    # Normalize from [0, 255] to [0.0, 1.0]\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [28*28]) / 255.0\n",
    "    label = tf.decode_raw(features['label'], tf.uint8)\n",
    "    label = tf.reshape(label, [])\n",
    "    label = tf.one_hot(label, 10, dtype=tf.int32)\n",
    "    return image, label\n",
    "\n",
    "  def input_fn():\n",
    "    files = tf.data.Dataset.list_files(file_pattern)\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      dataset = dataset.cache()\n",
    "      dataset = dataset.shuffle(10000)\n",
    "      dataset = dataset.repeat(count=count)\n",
    "      \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "\n",
    "    return features, labels\n",
    "  \n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = generate_input_fn(\n",
    "    file_pattern='{}/train.tfrecord'.format(DATA_DIR),\n",
    "    mode=tf.estimator.ModeKeys.TRAIN,\n",
    "    batch_size=BATCH_SIZE, count=N_EPOCHS)\n",
    "\n",
    "eval_input_fn = generate_input_fn(\n",
    "    file_pattern='{}/eval.tfrecord'.format(DATA_DIR),\n",
    "    mode=tf.estimator.ModeKeys.EVAL, count=1)\n",
    "\n",
    "test_input_fn = generate_input_fn(\n",
    "    file_pattern='{}/test.tfrecord'.format(DATA_DIR),\n",
    "    mode=tf.estimator.ModeKeys.PREDICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_model():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.InputLayer(input_shape=[28*28]))\n",
    "  model.add(tf.keras.layers.Dense(300, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.SGD(lr=0.005),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.keras.estimator.model_to_estimator(model, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = estimator.predict(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_name = model.input.name.split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity function\n",
    "def preprocess(x):\n",
    "  return tf.reshape(x, [-1, 28*28]) / 255.0\n",
    "\n",
    "def serving_input_fn():\n",
    "  receiver_tensor = {'X': tf.placeholder(tf.float32, shape=[None, 28, 28])}\n",
    "  features = {input_feature_name: tf.map_fn(preprocess, receiver_tensor['X'])}\n",
    "  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_export_dir = estimator.export_savedmodel(\n",
    "    export_dir_base=EXPORT_DIR, serving_input_receiver_fn=serving_input_fn)\n",
    "export_dir = b_export_dir.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!saved_model_cli show --dir {export_dir}\n",
    "#!saved_model_cli show --dir {export_dir} --tag_set serve\n",
    "!saved_model_cli show --dir {export_dir} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXAMPLES = 1000\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "  export_dir=export_dir, signature_def_key='serving_default')\n",
    "\n",
    "_X = X_test[:N_EXAMPLES]\n",
    "_y = y_test[:N_EXAMPLES]\n",
    "\n",
    "output = predictor_fn({'X': _X})\n",
    "class_ids = np.argmax(output['dense_3'], axis=2).reshape(-1)\n",
    "\n",
    "accuracy = np.sum(_y == class_ids)/float(N_EXAMPLES)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_and_Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.train\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=10000)\n",
    "\n",
    "# Saved Model\n",
    "exporter = tf.estimator.LatestExporter(\n",
    "    name='export', serving_input_receiver_fn=serving_input_fn)\n",
    "\n",
    "# Validation option.\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=eval_input_fn,\n",
    "    steps=None,          # stop when it catches EOF Exception\n",
    "    start_delay_secs=60, # start evaluating after N seconds\n",
    "    throttle_secs=60,\n",
    "    exporters=exporter,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
