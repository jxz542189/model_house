{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPU training for CIFAR10 dataset\n",
    "\n",
    "Helpful references:\n",
    "- https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/distribute/MirroredStrategy\n",
    "- https://www.youtube.com/watch?v=-h0cWBiQ8s8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    feature={'label': tf.FixedLenFeature((), tf.int64),\n",
    "             'image': tf.FixedLenFeature((), tf.string, default_value=\"\")}\n",
    "    parsed = tf.parse_single_example(example, feature)\n",
    "    image = tf.decode_raw(parsed['image'],tf.float64)\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image = tf.reshape(image,[32,32,3])\n",
    "    return image, parsed['label']\n",
    "\n",
    "def image_scaling(x):\n",
    "    return tf.image.per_image_standardization(x)\n",
    "\n",
    "def distort(x):\n",
    "    x = tf.image.resize_image_with_crop_or_pad(x, 40, 40)\n",
    "    x = tf.random_crop(x, [32, 32, 3])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x\n",
    "\n",
    "def dataset_input_fn(params):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        params['filenames'],num_parallel_reads=params['threads'])\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=params['threads'])\n",
    "    dataset = dataset.map(lambda x,y: (image_scaling(x),y),num_parallel_calls=params['threads'])\n",
    "    if params['mode']==tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.map(lambda x,y: (distort(x),y),num_parallel_calls=params['threads'])\n",
    "        dataset = dataset.shuffle(buffer_size=params['shuffle_buff'])\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(params['batch'])\n",
    "    dataset = dataset.prefetch(8*params['batch'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = tf.gfile.Glob('./data/cifar10_data_00*')\n",
    "eval_files   = tf.gfile.Glob('./data/cifar10_data_01*')\n",
    "\n",
    "train_params = {'filenames': train_files,\n",
    "                'mode': tf.estimator.ModeKeys.TRAIN,\n",
    "                'threads': 16,\n",
    "                'shuffle_buff': 100000,\n",
    "                'batch': 200}\n",
    "\n",
    "eval_params  = {'filenames': eval_files,\n",
    "                'mode': tf.estimator.ModeKeys.EVAL,\n",
    "                'threads': 8,\n",
    "                'batch': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params  = {'drop_out': 0.2, 'dense_units': 1024, 'learning_rate': 1e-3, 'log': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv(x,kernel,name,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable(initializer=tf.truncated_normal(shape=kernel,stddev=0.01),name='W')\n",
    "        b = tf.get_variable(initializer=tf.constant(0.0,shape=[kernel[3]]),name='b')\n",
    "        conv = tf.nn.conv2d(x, W, strides=[1,1,1,1],padding='SAME')\n",
    "        activation = tf.nn.relu(tf.add(conv,b))\n",
    "        pool = tf.nn.max_pool(activation,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        if log==True:\n",
    "            tf.summary.histogram(\"weights\",W)\n",
    "            tf.summary.histogram(\"biases\",b)\n",
    "            tf.summary.histogram(\"activations\",activation)\n",
    "        return pool\n",
    "\n",
    "def _dense(x,size_in,size_out,name,relu=False,log=False):\n",
    "    with tf.variable_scope(name):\n",
    "        flat = tf.reshape(x,[-1,size_in])\n",
    "        W = tf.get_variable(initializer=tf.truncated_normal([size_in,size_out],stddev=0.1),name='W')\n",
    "        b = tf.get_variable(initializer=tf.constant(0.0,shape=[size_out]),name='b')\n",
    "        activation = tf.add(tf.matmul(flat,W),b)\n",
    "        if relu==True:\n",
    "            activation = tf.nn.relu(activation)\n",
    "        if log==True:\n",
    "            tf.summary.histogram(\"weights\",W)\n",
    "            tf.summary.histogram(\"biases\",b)\n",
    "            tf.summary.histogram(\"activations\",activation)\n",
    "        return activation\n",
    "    \n",
    "def _model(features, mode, params):\n",
    "    input_layer = tf.reshape(features, [-1, 32, 32, 3])\n",
    "    conv1 = _conv(input_layer, kernel=[5,5,3,128], name='conv1', log=params['log'])\n",
    "    conv2 = _conv(conv1, kernel=[5,5,128,128], name='conv2', log=params['log'])\n",
    "    conv3 = _conv(conv2, kernel=[3,3,128,256], name='conv3', log=params['log'])\n",
    "    conv4 = _conv(conv3, kernel=[3,3,256,512], name='conv4', log=params['log'])\n",
    "    dense = _dense(conv4, size_in=2*2*512, size_out=params['dense_units'],\n",
    "                   name='Dense', relu=True, log=params['log'])\n",
    "    \n",
    "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
    "        dense = tf.nn.dropout(dense, params['drop_out'])\n",
    "        \n",
    "    logits = _dense(dense, size_in=params['dense_units'],\n",
    "                    size_out=10, name='Output', relu=False, log=params['log'])\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    logits = _model(features, mode, params)\n",
    "    predictions = {\"logits\": logits,\n",
    "                   \"classes\": tf.argmax(input=logits,axis=1),\n",
    "                   \"probabilities\": tf.nn.softmax(logits,name='softmax')}\n",
    "    export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
    "    \n",
    "    if (mode==tf.estimator.ModeKeys.TRAIN or mode==tf.estimator.ModeKeys.EVAL):\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        learning_rate = tf.train.exponential_decay(params['learning_rate'],\n",
    "                                                   tf.train.get_global_step(),\n",
    "                                                   decay_steps=100000,\n",
    "                                                   decay_rate=0.96)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "        metrics = {'accuracy':accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,loss=loss, eval_metric_ops=metrics)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, predictions=predictions, export_outputs=export_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cnn_model/tflow_model_'\n",
    "name = name + 'dense' + str(model_params['dense_units']) + '_'\n",
    "name = name + 'drop' + str(model_params['drop_out']) + '_'\n",
    "name = name + 'lr' + str(model_params['learning_rate']) + '_'\n",
    "name = name + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "model_dir  = os.path.join('./',name)\n",
    "\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=8)\n",
    "config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs=300,\n",
    "    keep_checkpoint_max=5,\n",
    "    session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True),\n",
    "    train_distribute=distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, model_dir=model_dir, params=model_params, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(input_fn=lambda: dataset_input_fn(train_params), max_steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(input_fn=lambda: dataset_input_fn(eval_params), steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
