{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook describes how to implement distributed tensorflow code.\n",
    "\n",
    "Content of this notebook is shown below.\n",
    "\n",
    "0. Prepare CIFAR-10 Dataset (TFRecords Format)\n",
    "1. Define parameters\n",
    "2. Define data input pipeline\n",
    "3. Define features\n",
    "4. Define a model\n",
    "5. Define serving function\n",
    "6. Train, evaluate and export a model\n",
    "7. Evaluate with Estimator\n",
    "8. Prediction with Exported Model\n",
    "8. Distributed Training with Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare CIFAR-10 Dataset (TFRecords Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_FILENAME = 'cifar-10-python.tar.gz'\n",
    "CIFAR_DOWNLOAD_URL = 'http://www.cs.toronto.edu/~kriz/' + CIFAR_FILENAME\n",
    "CIFAR_LOCAL_FOLDER = 'cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_and_extract(data_dir):\n",
    "  tf.contrib.learn.datasets.base.maybe_download(CIFAR_FILENAME, data_dir, CIFAR_DOWNLOAD_URL)\n",
    "  tarfile.open(os.path.join(data_dir, CIFAR_FILENAME), 'r:gz').extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_names():\n",
    "  \"\"\"Returns the file names expected to exist in the input_dir.\"\"\"\n",
    "  file_names = {}\n",
    "  file_names['train'] = ['data_batch_%d' % i for i in xrange(1, 5)]\n",
    "  file_names['validation'] = ['data_batch_5']\n",
    "  file_names['eval'] = ['test_batch']\n",
    "  return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_pickle_from_file(filename):\n",
    "  with tf.gfile.Open(filename, 'r') as f:\n",
    "    data_dict = cPickle.load(f)\n",
    "  return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_tfrecord(input_files, output_file):\n",
    "  \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "  print('Generating %s' % output_file)\n",
    "  with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "    for input_file in input_files:\n",
    "      data_dict = _read_pickle_from_file(input_file)\n",
    "      data = data_dict['data']\n",
    "      labels =  data_dict['labels']\n",
    "      num_entries_in_batch = len(labels)\n",
    "      for i in range(num_entries_in_batch):\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "          feature={\n",
    "            'image': _bytes_feature(data[i].tobytes()),\n",
    "            'label': _int64_feature(labels[i])\n",
    "          }))\n",
    "        record_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords_files(data_dir='cifar-10'):\n",
    "  _download_and_extract(data_dir)\n",
    "  file_names = _get_file_names()\n",
    "  input_dir = os.path.join(data_dir, CIFAR_LOCAL_FOLDER)\n",
    "\n",
    "  for mode, files in file_names.items():\n",
    "    input_files = [os.path.join(input_dir, f) for f in files]\n",
    "    output_file = os.path.join(data_dir, mode+'.tfrecords')\n",
    "    try:\n",
    "      os.remove(output_file)\n",
    "    except OSError:\n",
    "      pass\n",
    "    # Convert to tf.train.Example and write to TFRecords.\n",
    "    _convert_to_tfrecord(input_files, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecords_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS():\n",
    "  pass\n",
    "\n",
    "FLAGS.batch_size = 200\n",
    "FLAGS.max_steps = 1000\n",
    "FLAGS.eval_steps = 100\n",
    "FLAGS.save_checkpoints_steps = 100\n",
    "FLAGS.tf_random_seed = 19851211\n",
    "FLAGS.model_name = 'cnn-model-02'\n",
    "FLAGS.use_checkpoint = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define data input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(serialized_example):\n",
    "  features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "      'image': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "  \n",
    "  image = tf.decode_raw(features['image'], tf.uint8)\n",
    "  image.set_shape([IMAGE_DEPTH * IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "  image = tf.reshape(image, [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "  image = tf.cast(tf.transpose(image, [1, 2, 0]), tf.float32)\n",
    "  \n",
    "  label = tf.cast(features['label'], tf.int32)\n",
    "  label = tf.one_hot(label, NUM_CLASSES)\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, is_training=False):\n",
    "  \"\"\"Preprocess a single image of layout [height, width, depth].\"\"\"\n",
    "  if is_training:\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_image_with_crop_or_pad(\n",
    "        image, IMAGE_HEIGHT + 8, IMAGE_WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  image = tf.image.per_image_standardization(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_fn(file_names, mode=tf.estimator.ModeKeys.EVAL, batch_size=1):\n",
    "  def _input_fn():\n",
    "    dataset = tf.data.TFRecordDataset(filenames=file_names)\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    if is_training:\n",
    "      buffer_size = batch_size * 2 + 1\n",
    "      dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    # Transformation\n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.map(\n",
    "      lambda image, label: (preprocess_image(image, is_training), label))\n",
    "\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "\n",
    "    images, labels = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    features = {'images': images}\n",
    "    return features, labels\n",
    "  \n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns():\n",
    "  feature_columns = {\n",
    "    'images': tf.feature_column.numeric_column('images', (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH)),\n",
    "  }\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = get_feature_columns()\n",
    "print(\"Feature Columns: {}\".format(feature_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "  # 1st Convolutional Layer                                                                                                                 \n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=images, filters=64, kernel_size=[5, 5], padding='same',\n",
    "      activation=tf.nn.relu, name='conv1')\n",
    "  pool1 = tf.layers.max_pooling2d(\n",
    "      inputs=conv1, pool_size=[3, 3], strides=2, name='pool1')\n",
    "  norm1 = tf.nn.lrn(\n",
    "      pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "  # 2nd Convolutional Layer                                                                                                                 \n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=norm1, filters=64, kernel_size=[5, 5], padding='same',\n",
    "      activation=tf.nn.relu, name='conv2')\n",
    "  norm2 = tf.nn.lrn(\n",
    "      conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "  pool2 = tf.layers.max_pooling2d(\n",
    "      inputs=norm2, pool_size=[3, 3], strides=2, name='pool2')\n",
    "\n",
    "  # Flatten Layer                                                                                                                           \n",
    "  shape = pool2.get_shape()\n",
    "  pool2_ = tf.reshape(pool2, [-1, shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "  # 1st Fully Connected Layer                                                                                                               \n",
    "  dense1 = tf.layers.dense(\n",
    "      inputs=pool2_, units=384, activation=tf.nn.relu, name='dense1')\n",
    "\n",
    "  # 2nd Fully Connected Layer                                                                                                               \n",
    "  dense2 = tf.layers.dense(\n",
    "      inputs=dense1, units=192, activation=tf.nn.relu, name='dense2')\n",
    "\n",
    "  # 3rd Fully Connected Layer (Logits)                                                                                                      \n",
    "  logits = tf.layers.dense(\n",
    "      inputs=dense2, units=NUM_CLASSES, activation=tf.nn.relu, name='logits')\n",
    "\n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  # Create the input layers from the features                                                                                               \n",
    "  feature_columns = list(get_feature_columns().values())\n",
    "\n",
    "  images = tf.feature_column.input_layer(\n",
    "    features=features, feature_columns=feature_columns)\n",
    "\n",
    "  images = tf.reshape(\n",
    "    images, shape=(-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH))\n",
    "\n",
    "  # Calculate logits through CNN                                                                                                            \n",
    "  logits = inference(images)\n",
    "\n",
    "  if mode in (tf.estimator.ModeKeys.PREDICT, tf.estimator.ModeKeys.EVAL):\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "\n",
    "  if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    label_indices = tf.argmax(input=labels, axis=1)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=labels, logits=logits)\n",
    "    tf.summary.scalar('cross_entropy', loss)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'classes': predicted_indices,\n",
    "        'probabilities': probabilities\n",
    "    }\n",
    "    export_outputs = {\n",
    "        'predictions': tf.estimator.export.PredictOutput(predictions)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define a serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "  receiver_tensor = {'images': tf.placeholder(\n",
    "    shape=[None, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH], dtype=tf.float32)}\n",
    "  features = {'images': tf.map_fn(preprocess_image, receiver_tensor['images'])}\n",
    "  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train, evaluate and export a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'trained_models/{}'.format(FLAGS.model_name)\n",
    "train_data_files = ['cifar-10/train.tfrecords']\n",
    "valid_data_files = ['cifar-10/validation.tfrecords']\n",
    "test_data_files = ['cifar-10/eval.tfrecords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "  save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "  tf_random_seed=FLAGS.tf_random_seed,\n",
    "  model_dir=model_dir\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "\n",
    "# There is another Exporter named FinalExporter\n",
    "exporter = tf.estimator.LatestExporter(\n",
    "  name='Servo',\n",
    "  serving_input_receiver_fn=serving_input_fn,\n",
    "  assets_extra=None,\n",
    "  as_text=False,\n",
    "  exports_to_keep=5)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "  input_fn=generate_input_fn(file_names=train_data_files,\n",
    "                             mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                             batch_size=FLAGS.batch_size),\n",
    "  max_steps=FLAGS.max_steps)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "  input_fn=generate_input_fn(file_names=valid_data_files,\n",
    "                             mode=tf.estimator.ModeKeys.EVAL,\n",
    "                             batch_size=FLAGS.batch_size),\n",
    "  steps=FLAGS.eval_steps, exporters=exporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLAGS.use_checkpoint:\n",
    "  print(\"Removing previous artifacts...\")\n",
    "  shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation with Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = generate_input_fn(file_names=test_data_files,\n",
    "                                  mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                  batch_size=1000)\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "print(estimator.evaluate(input_fn=test_input_fn, steps=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prediction with Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = model_dir + '/export/Servo/'\n",
    "saved_model_dir = os.path.join(export_dir, os.listdir(export_dir)[-1]) \n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "  export_dir = saved_model_dir,\n",
    "  signature_def_key='predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "data_dict = _read_pickle_from_file('cifar-10/cifar-10-batches-py/test_batch')\n",
    "\n",
    "N = 1000\n",
    "images = data_dict['data'][:N].reshape([N, 3, 32, 32]).transpose([0, 2, 3, 1])\n",
    "labels = data_dict['labels'][:N]\n",
    "\n",
    "output = predictor_fn({'images': images})\n",
    "accuracy = numpy.sum(\n",
    "  [ans==ret for ans, ret in zip(labels, output['classes'])]) / float(N)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Distributed Training with Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Set environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = 'YOUR-PROJECT-ID' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'YOUR-BUCKET-NAME' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'BUCKET-REGION' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Set permission to BUCKET (NOTE: Create bucket beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print response['serviceAccount']\")\n",
    "\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Copy TFRecords files to GCS BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo ${BUCKET}\n",
    "gsutil -m rm -rf gs://${BUCKET}/cifar-10\n",
    "gsutil -m cp cifar-10/*.tfrecords gs://${BUCKET}/cifar-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Run distributed training with Cloud MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/trained_models_3cpu\n",
    "JOBNAME=sm_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=cnn-model-02.task \\\n",
    "   --package-path=\"$(pwd)/trainer/cnn-model-02\" \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --config=config_3cpu.yaml \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --bucket_name=$BUCKET \\\n",
    "   --train_data_pattern=cifar-10/train*.tfrecords \\\n",
    "   --eval_data_pattern=cifar-10/eval*.tfrecords  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --max_steps=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://$BUCKET/trained_models_3gpu\n",
    "JOBNAME=sm_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=cnn-model-02.task \\\n",
    "   --package-path=\"$(pwd)/trainer/cnn-model-02\" \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --config=config_3gpu.yaml \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --bucket_name=$BUCKET \\\n",
    "   --train_data_pattern=cifar-10/train*.tfrecords \\\n",
    "   --eval_data_pattern=cifar-10/eval*.tfrecords  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --max_steps=10000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
